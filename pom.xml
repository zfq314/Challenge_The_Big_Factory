<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>com.bigdata.zfq</groupId>
    <artifactId>Challenge_The_Big_Factory</artifactId>
    <!--  packaging的默认打包类型是jar
        所有的父工程打包方式都需要设置成pom
    -->
    <packaging>pom</packaging>
    <version>1.0-SNAPSHOT</version>
    <modules>
        <module>flinkcdc</module>
        <module>flink-1.13.0</module>
        <module>hive</module>
        <module>linux</module>
        <module>mysql</module>
        <module>data_warehouse</module>
        <module>zookeeper</module>
        <module>algorithm</module>
        <module>clickhouse</module>
    </modules>

    <properties>
        <java.version>1.8</java.version>
        <flink.version>1.13.0</flink.version>
        <hive.version>1.2.1</hive.version>
        <hadoop-version>2.7.2</hadoop-version>
        <scala-binary-version>2.11</scala-binary-version>
        <log4j-version>2.14.0</log4j-version>
        <slf4j.version>1.7.30</slf4j.version>
        <gson-version>2.8.2</gson-version>
        <mysql-java-verion>8.0.13</mysql-java-verion>
        <hbase.version>1.3.1</hbase.version>
    </properties>
    <!--
      依赖配置：
            目前这里的配置的依赖所引入的jar包在此工程下的所有子工程都会被引入
    -->
    <dependencies>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-java</artifactId>
            <version>${flink.version}</version>
        </dependency>
        <!-- 引入 Flink 相关依赖-->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-streaming-java_${scala-binary-version}</artifactId>
            <version>${flink.version}</version>
        </dependency>

        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-clients_${scala-binary-version}</artifactId>
            <version>${flink.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-streaming-scala_${scala-binary-version}</artifactId>
            <version>${flink.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-api-java-bridge_${scala-binary-version}</artifactId>
            <version>${flink.version}</version>
        </dependency>

        <!-- 这里主要添加的依赖是一个“计划器”（planner），它是Table API的核心组件，负责提供运行时环境，
       并生成程序的执行计划。这里我们用到的是新版的blink planner。由于Flink安装包的lib目录下会自带planner，
       所以在生产集群环境中提交的作业不需要打包这个依赖。
       而在Table API的内部实现上，部分相关的代码是用 Scala 实现的，所以还需要额外添加一个Scala版流处理的相关依赖。
       另外，如果想实现自定义的数据格式来做序列化，可以引入下面的依赖：
       -->
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-planner-blink_${scala-binary-version}</artifactId>
            <version>${flink.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-streaming-scala_${scala-binary-version}</artifactId>
            <version>${flink.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-connector-hbase-1.4_${scala-binary-version}</artifactId>
            <version>${flink.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-table-common</artifactId>
            <version>${flink.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.flink</groupId>
            <artifactId>flink-connector-hive_${scala-binary-version}</artifactId>
            <version>${flink.version}</version>
        </dependency>
        <!-- Hive Dependency -->

        <!-- Hive 依赖 -->
        <dependency>
            <groupId>org.apache.hive</groupId>
            <artifactId>hive-exec</artifactId>
            <version>${hive.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <version>${hadoop-version}</version>
        </dependency>
        <!-- 引入日志管理相关依赖-->
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-api</artifactId>
            <version>${slf4j.version}</version>
        </dependency>
        <!--日志依赖包-->
        <dependency>
            <groupId>org.slf4j</groupId>
            <artifactId>slf4j-log4j12</artifactId>
            <version>${slf4j.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.logging.log4j</groupId>
            <artifactId>log4j-to-slf4j</artifactId>
            <version>${log4j-version}</version>
        </dependency>
        <dependency>
            <groupId>com.google.code.gson</groupId>
            <artifactId>gson</artifactId>
            <version>${gson-version}</version>
        </dependency>
        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <version>${mysql-java-verion}</version>
        </dependency>
        <!--to HBASE-->
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-client</artifactId>
            <version>${hbase.version}</version>
        </dependency>
    </dependencies>
    <!--
       依赖管理：
             这里的配置的依赖只是对依赖版本的管理配置，子工程并不会直接引入
             如果子工程要需要引入只需要加入如下标签：
              <dependency>
                <groupId>mysql</groupId>
                <artifactId>mysql-connector-java</artifactId>
              </dependency>
             这样就可以引入mysql的驱动了，这样的好处就是可以在父工程统一一下整个工程的jar包依赖版本
             而且如果有的工程不需要一些jar就可以不进行引入
-->
    <dependencyManagement>

    </dependencyManagement>
</project>